{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os\n",
    "import pydicom\n",
    "from glob import glob\n",
    "!pip install dicomsdl\n",
    "import dicomsdl\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def visualize_image(orig_image, image):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(orig_image, cmap='gray')\n",
    "    axes[0].set_title('Original DICOM Image')\n",
    "    axes[1].imshow(image, cmap='gray')\n",
    "    axes[1].set_title('Processed DICOM Image')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "def __dataset__to_numpy_image(self, index=0):\n",
    "    info = self.getPixelDataInfo()\n",
    "    dtype = info['dtype']\n",
    "    if info['SamplesPerPixel'] != 1:\n",
    "        raise RuntimeError('SamplesPerPixel != 1')\n",
    "    else:\n",
    "        shape = [info['Rows'], info['Cols']]\n",
    "    outarr = np.empty(shape, dtype=dtype)\n",
    "    self.copyFrameData(index, outarr)\n",
    "    return outarr\n",
    "dicomsdl._dicomsdl.DataSet.to_numpy_image = __dataset__to_numpy_image\n",
    "\n",
    "\n",
    "\n",
    "def glob_sorted(path):\n",
    "    return sorted(glob(path), key=lambda x: int(x.split('/')[-1].split('.')[0]))\n",
    "\n",
    "def get_rescaled_image(dcm, img):\n",
    "    resI, resS = dcm.RescaleIntercept, dcm.RescaleSlope\n",
    "    img = resS * img + resI\n",
    "    return img\n",
    "\n",
    "def get_windowed_image(img, WL=50, WW=400):\n",
    "    upper, lower = WL+WW//2, WL-WW//2\n",
    "    X = np.clip(img.copy(), lower, upper)\n",
    "    X = X - np.min(X)\n",
    "    X = X / np.max(X)\n",
    "    X = (X*255.0).astype('uint8')\n",
    "\n",
    "    return X\n",
    "\n",
    "\n",
    "def load_volume(dcms):\n",
    "    volume = []\n",
    "    pos_zs = []\n",
    "    k = 1\n",
    "\n",
    "    for dcm_path in dcms:\n",
    "        pydcm = pydicom.dcmread(dcm_path)\n",
    "\n",
    "        pos_z = pydcm[(0x20, 0x32)].value[-1]\n",
    "        pos_zs.append(pos_z)\n",
    "\n",
    "        dcm = dicomsdl.open(dcm_path)\n",
    "\n",
    "        orig_image = dcm.to_numpy_image()\n",
    "\n",
    "        image = get_rescaled_image(dcm, orig_image)\n",
    "\n",
    "        image = get_windowed_image(image)\n",
    "\n",
    "        if np.min(image)<0:\n",
    "            image = image + np.abs(np.min(image))\n",
    "\n",
    "        image = image / image.max()\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "        volume.append(image)\n",
    "\n",
    "        # Visualize the image\n",
    "        #if k == 1:\n",
    "        #    k +=1\n",
    "        #    print(image.shape)\n",
    "        #    visualize_image(orig_image, image)\n",
    "\n",
    "\n",
    "    return np.stack(volume)\n",
    "\n",
    "\n",
    "\n",
    "def process_volume(volume, patient):\n",
    "    volume = np.stack([cv2.resize(x, (128, 128)) for x in volume])\n",
    "\n",
    "    #to visualize the squished image\n",
    "    #print(volume.shape)\n",
    "    #image = volume[0]\n",
    "    #visualize_image(image, image)\n",
    "\n",
    "    #we don't need this, this was some pre-processing done for pytorch input, we just want to download the images\n",
    "    '''\n",
    "    volumes = []\n",
    "    cuts = [(x, x+32) for x in np.arange(0, volume.shape[0], 32)[:-1]]\n",
    "    \n",
    "    if cuts:\n",
    "        for cut in cuts:\n",
    "            volumes.append(volume[cut[0]:cut[1]])\n",
    "        volumes = np.stack(volumes)\n",
    "    else:\n",
    "        volumes = np.zeros((1, 32, 128, 128), dtype=np.uint8)\n",
    "        volumes[0, :len(volume)] = volume\n",
    "    \n",
    "    if cuts:\n",
    "        last_volume = np.zeros((1, 32, 128, 128), dtype=np.uint8)\n",
    "        last_volume[0, :volume[cuts[-1][1]:].shape[0]] =  volume[cuts[-1][1]:]\n",
    "        volumes = np.concatenate([volumes, last_volume])\n",
    "    \n",
    "    volumes = torch.as_tensor(volumes).float()\n",
    "    \n",
    "    return volumes\n",
    "    '''\n",
    "\n",
    "    # Create a folder to save the images if it doesn't exist\n",
    "    output_folder = f\"/kaggle/working/output/{patient}\"\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Save each image in the numpy array\n",
    "    for i in range(len(volume)):\n",
    "        # Generate the filename for the image\n",
    "        filename = os.path.join(output_folder, f\"{i}.png\")\n",
    "\n",
    "        # Plot and save the image using matplotlib\n",
    "        plt.imsave(filename, volume[i], cmap='gray')  # Assuming grayscale images, adjust cmap as needed\n",
    "\n",
    "\n",
    "\n",
    "def get_volume_data(grd, step=96, stride=1, stride_cutoff=200):\n",
    "    volumes = []\n",
    "\n",
    "    if len(grd)>stride_cutoff:\n",
    "        grd = grd[::stride]\n",
    "\n",
    "    take_last = False\n",
    "    if not str(len(grd)/step).endswith('.0'):\n",
    "        take_last = True\n",
    "\n",
    "    started = False\n",
    "    for i in range(len(grd)//step):\n",
    "        rows = grd[i*step:(i+1)*step]\n",
    "\n",
    "        if len(rows)!=step:\n",
    "            rows = pd.DataFrame([rows.iloc[int(x*len(rows))] for x in np.arange(0, 1, 1/step)])\n",
    "\n",
    "        volumes.append(rows)\n",
    "\n",
    "        started = True\n",
    "\n",
    "    if not started:\n",
    "        rows = grd\n",
    "        rows = pd.DataFrame([rows.iloc[int(x*len(rows))] for x in np.arange(0, 1, 1/step)])\n",
    "        volumes.append(rows)\n",
    "\n",
    "    if take_last:\n",
    "        rows = grd[-step:]\n",
    "        if len(rows)==step:\n",
    "            volumes.append(rows)\n",
    "\n",
    "    return volumes\n",
    "\n",
    "\n",
    "# Define your preprocessing functions here\n",
    "IMAGE_FOLDER = '/kaggle/input/rsna-2023-abdominal-trauma-detection/train_images/'\n",
    "\n",
    "patients = os.listdir(f\"{IMAGE_FOLDER}\")\n",
    "sorted_patients = sorted(patients, key=lambda x: int(x))\n",
    "arange = range(3147, 3148)\n",
    "\n",
    "for i in tqdm(arange):\n",
    "    patient = sorted_patients[i]\n",
    "    studies = os.listdir(f'{IMAGE_FOLDER}/{patient}')\n",
    "    #take only the first study\n",
    "    study = studies[0]\n",
    "    files = glob_sorted(f\"{IMAGE_FOLDER}/{patient}/{study}/*\")\n",
    "\n",
    "    # shape = (number of images, height, width)\n",
    "    volume = load_volume(files)\n",
    "\n",
    "    volumes = process_volume(volume, patient)\n",
    "\n",
    "output_folder = f\"/kaggle/working/output\"\n",
    "with zipfile.ZipFile(f\"/kaggle/working/batch_{arange}.zip\", 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "    for root, _, files in os.walk(output_folder):\n",
    "        for file in files:\n",
    "            zipf.write(os.path.join(root, file), os.path.relpath(os.path.join(root, file), output_folder))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7931ea0c9885858"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "def delete_folder(folder_path):\n",
    "    try:\n",
    "        # Attempt to remove the folder and its contents\n",
    "        shutil.rmtree(folder_path)\n",
    "        print(f\"Folder '{folder_path}' successfully deleted.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while deleting folder '{folder_path}': {e}\")\n",
    "\n",
    "# Example usage:\n",
    "folder_to_delete = \"/kaggle/working/output\"\n",
    "\n",
    "delete_folder(folder_to_delete)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e7909871ecac24e6"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
