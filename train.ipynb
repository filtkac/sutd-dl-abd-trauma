{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# !pip install pandas tqdm torch scikit-learn\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import models\n",
    "from utils import save_model, load_model, upload_models_hf, class_weights\n",
    "from data.dataset import PatientDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"dataset/reduced/train\"\n",
    "labels_path = \"dataset/reduced/train.csv\"\n",
    "batch_size = 1\n",
    "model_type = \"cnn\"\n",
    "cuda = False\n",
    "lr = 1e-3\n",
    "epochs = 5\n",
    "depth = 64 # number of CT slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by filtering out the dataframe for any patients where we are missing CT scans for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2886, 6)\n"
     ]
    }
   ],
   "source": [
    "entries = os.listdir(images_path)\n",
    "patient_ids = [int(entry) for entry in entries if os.path.isdir(os.path.join(images_path, entry))]\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "df = df[df['patient_id'].isin(patient_ids)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we perform a standard train-validation-test split of 80-10-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2308, 6)\n",
      "(289, 6)\n",
      "(289, 6)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, val_test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>bowel</th>\n",
       "      <th>extravastion</th>\n",
       "      <th>kidney</th>\n",
       "      <th>liver</th>\n",
       "      <th>spleen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>38343</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>29412</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>63193</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>23709</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2408</th>\n",
       "      <td>58547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id  bowel  extravastion  kidney  liver  spleen\n",
       "1426       38343      0             1       0      0       1\n",
       "964        29412      0             0       0      0       0\n",
       "2608       63193      0             0       0      0       0\n",
       "662        23709      0             0       0      0       0\n",
       "2408       58547      0             0       0      0       0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = class_weights(train_data)\n",
    "weights = torch.tensor(list(weights.values())).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeding this data into the pytorch dataset object we now have our dataloaders ready for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 128, 128])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PatientDataset(images_path, train_data, n_slices=depth)\n",
    "val_dataset = PatientDataset(images_path, val_data, n_slices=depth)\n",
    "test_dataset = PatientDataset(images_path, test_data, n_slices=depth)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# get one sample\n",
    "inputs, labels = train_dataset[0]\n",
    "\n",
    "print(inputs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to checkpoints/test.pth\n",
      "Model loaded from checkpoints/test.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2308 [00:07<?, ?it/s, loss=0.064]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "[EPOCH 0] LOSS train=0.6395382642745971 val=0.00020377794506228094\n",
      "Model saved to checkpoints/BEST_model_20240413_160742_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2308 [00:06<?, ?it/s, loss=0.699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "[EPOCH 1] LOSS train=6.987225341796875 val=0.0\n",
      "Model saved to checkpoints/BEST_model_20240413_160742_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2308 [00:06<?, ?it/s, loss=0.0121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "[EPOCH 2] LOSS train=0.12147411108016967 val=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2308 [00:14<?, ?it/s, loss=3.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "[EPOCH 3] LOSS train=34.78602905273438 val=0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2308 [00:12<?, ?it/s, loss=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation...\n",
      "[EPOCH 4] LOSS train=0.0 val=0.0\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"cnn\":\n",
    "    model = models.ConvNet3D(\n",
    "        in_channels=inputs.shape[0],\n",
    "        out_channels=labels.shape[0],\n",
    "        depth=inputs.shape[1],\n",
    "        height=inputs.shape[2],\n",
    "        width=inputs.shape[3],\n",
    "    )\n",
    "elif model_type == \"unet\":\n",
    "    model = ...\n",
    "else:\n",
    "    raise ValueError(\"Invalid model selected for training.\")\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# test save and loader functions\n",
    "os.makedirs(\"checkpoints\", exist_ok = True) # create ckpt dir\n",
    "os.makedirs(\"plots\", exist_ok = True) # create plots dir\n",
    "save_model(model, \"checkpoints/test.pth\")\n",
    "load_model(model, \"checkpoints/test.pth\")\n",
    "os.remove(\"checkpoints/test.pth\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(reduction=\"none\")  # multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train() # set model to train\n",
    "\n",
    "    # creating loss tracker\n",
    "    running_loss = 0.0\n",
    "    running_vloss = 0.0\n",
    "    batch_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    for i, (inputs, labels) in pbar:\n",
    "        if cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # compute predictions + loss\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = (loss * weights).mean()\n",
    "\n",
    "        pred = (torch.sigmoid(outputs) > 0.5).int()\n",
    "        total += labels.shape[0]\n",
    "        correct += torch.sum(torch.all(pred == labels, dim=1))\n",
    "\n",
    "        # perform backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            batch_loss = batch_loss / 10 # loss per batch\n",
    "            pbar.set_postfix({'loss': round(batch_loss, 5)})\n",
    "            batch_loss = 0.0\n",
    "    \n",
    "    train_accuracy = correct / total\n",
    "    train_accuracies.append((epoch, train_accuracy))\n",
    "\n",
    "    avg_loss = running_loss / (i + 1)\n",
    "    train_losses.append((epoch, avg_loss))\n",
    "\n",
    "    print(\"Validation...\")\n",
    "    model.eval() # set model to evaluation\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for (inputs, labels) in val_dataloader:\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_vloss += (loss * weights).mean().item()\n",
    "\n",
    "            pred = (torch.sigmoid(outputs) > 0.5).int()\n",
    "            total += labels.shape[0]\n",
    "            correct += torch.sum(torch.all(pred == labels, dim=1))\n",
    "    \n",
    "    val_accuracy = correct / total\n",
    "    val_accuracies.append((epoch, val_accuracy))\n",
    "    \n",
    "    avg_vloss = running_vloss / len(val_dataloader)\n",
    "    val_losses.append((epoch, avg_vloss))\n",
    "\n",
    "    print(f'[EPOCH {epoch}] LOSS : train={avg_loss} val={avg_vloss} | ACCURACY : train={train_accuracy} val={val_accuracy}')\n",
    "\n",
    "    # save model when\n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        save_model(model, f\"checkpoints/BEST_model_{timestamp}_{epoch}.pth\")\n",
    "\n",
    "    if epoch != 0 and epoch % 25 == 0:\n",
    "        save_model(model, f\"checkpoints/model_{timestamp}_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the training and validation loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs, t_loss = list(zip(*train_losses))\n",
    "_, v_loss = list(zip(*val_losses))\n",
    "_, acc = list(zip(*train_accuracies))\n",
    "_, v_acc = list(zip(*val_accuracies))\n",
    "\n",
    "plt.title(\"Loss Curve (batch_size={}, lr={})\".format(batch_size, lr))\n",
    "plt.plot(epochs, t_loss, label=\"Train\")\n",
    "plt.plot(epochs, v_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "plt.savefig(\"plots/loss.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"Accuracy Curve (batch_size={}, lr={})\".format(batch_size, lr))\n",
    "plt.plot(epochs, acc, label=\"Train\")\n",
    "plt.plot(epochs, v_acc, label=\"Validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.xticks(epochs)\n",
    "plt.savefig(\"plots/accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_models_hf(\"checkpoints/\", \"Pie31415\", \"abd-trauma-models\") # upload to huggingface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model(model, \"checkpoints/BEST_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = train_dataset[0]\n",
    "data = data.unsqueeze(0).cuda()\n",
    "outputs = model(data.float())\n",
    "probs = torch.sigmoid(outputs)\n",
    "pred = (probs > 0.5).int()\n",
    "\n",
    "print(f\"Reals: {labels}\")\n",
    "print(f\"Predictions: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
