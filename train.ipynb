{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import clear_output\n",
    "# !pip install pandas tqdm torch scikit-learn\n",
    "# clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import models\n",
    "from utils import save_model, load_model, upload_models_hf\n",
    "from data.dataset import PatientDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = \"dataset/reduced/train\"\n",
    "labels_path = \"dataset/reduced/train.csv\"\n",
    "batch_size = 1\n",
    "model_type = \"cnn\"\n",
    "cuda = False\n",
    "lr = 1e-3\n",
    "epochs = 100\n",
    "depth = 64 # number of CT slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = os.listdir(images_path)\n",
    "patient_ids = [int(entry) for entry in entries if os.path.isdir(os.path.join(images_path, entry))]\n",
    "\n",
    "df = pd.read_csv(labels_path)\n",
    "df = df[df['patient_id'].isin(patient_ids)]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "train_data, val_test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(val_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = PatientDataset(images_path, train_data, n_slices=depth)\n",
    "val_dataset = PatientDataset(images_path, val_data, n_slices=depth)\n",
    "test_dataset = PatientDataset(images_path, test_data, n_slices=depth)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# get one sample\n",
    "inputs, labels = train_dataset[0]\n",
    "\n",
    "print(inputs.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == \"cnn\":\n",
    "    model = models.ConvNet3D(\n",
    "        in_channels=inputs.shape[0],\n",
    "        out_channels=labels.shape[0],\n",
    "        depth=inputs.shape[1],\n",
    "        height=inputs.shape[2],\n",
    "        width=inputs.shape[3],\n",
    "    )\n",
    "elif model_type == \"unet\":\n",
    "    model = ...\n",
    "else:\n",
    "    raise ValueError(\"Invalid model selected for training.\")\n",
    "\n",
    "if cuda:\n",
    "    model = model.cuda()\n",
    "\n",
    "# test save and loader functions\n",
    "os.makedirs(\"checkpoints\", exist_ok = True)\n",
    "save_model(model, \"checkpoints/test.pth\")\n",
    "load_model(model, \"checkpoints/test.pth\")\n",
    "os.remove(\"checkpoints/test.pth\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # multi-label classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "best_vloss = 1_000_000.\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_vloss = 0.0\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(enumerate(train_dataloader), total=len(train_dataloader))\n",
    "    for i, (inputs, labels) in pbar:\n",
    "        if cuda:\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        # zero gradients for every batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        batch_loss += loss.item()\n",
    "        if i % 10 == 0:\n",
    "            batch_loss = batch_loss / 10 # loss per batch\n",
    "            pbar.set_postfix({'loss': round(batch_loss, 5)})\n",
    "            batch_loss = 0.0\n",
    "\n",
    "    avg_loss = running_loss / (i + 1)\n",
    "    train_losses.append((epoch, avg_loss))\n",
    "\n",
    "    print(\"Validation...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (inputs, labels) in val_dataloader:\n",
    "            if cuda:\n",
    "                inputs, labels = inputs.cuda(), labels.cuda()\n",
    "                \n",
    "            outputs = model(inputs.float())\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_vloss += loss.item()\n",
    "\n",
    "    avg_vloss = running_vloss / len(val_dataloader)\n",
    "    val_losses.append((epoch, avg_vloss))\n",
    "\n",
    "    print('[LOSS] train {} val {}'.format(avg_loss, avg_vloss))\n",
    "    \n",
    "    if avg_vloss < best_vloss:\n",
    "        best_vloss = avg_vloss\n",
    "        save_model(model, 'checkpoints/model_{}_{}'.format(timestamp, epoch))\n",
    "\n",
    "    if epoch != 0 and epoch % 5 == 0:\n",
    "        save_model(model, f\"checkpoints/model-e{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_iters, t_loss = list(zip(*train_losses))\n",
    "plt.title(\"Training Curve (batch_size={}, lr={})\".format(batch_size, lr))\n",
    "plt.plot(t_iters, t_loss, label=\"Train\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.show()\n",
    "\n",
    "v_iters, v_loss = list(zip(*val_losses))\n",
    "plt.title(\"Validation Curve (batch_size={}, lr={})\".format(batch_size, lr))\n",
    "plt.plot(v_iters, v_loss, label=\"Validation\")\n",
    "plt.xlabel(\"Validation Epochs\")    \n",
    "plt.ylabel(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_models_hf(\"checkpoints/\", \"Pie31415\", \"abd-trauma-models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "        pred = (outputs > 0.5).int()\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
